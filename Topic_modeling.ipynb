{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whirl-wind guide to Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resources referenced for further study.\n",
    "> http://nbviewer.jupyter.org/github/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb\n",
    "> http://nicschrading.com/project/Intro-to-NLP-with-spaCy/\n",
    "> http://mccormickml.com/2016/03/25/lsa-for-text-classification-tutorial/\n",
    "> http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/\n",
    "> http://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py\n",
    "> http://www.socher.org/index.php/Main/ImprovingWordRepresentationsViaGlobalContextAndMultipleWordPrototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 2.282s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data[:n_samples]\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 0.487s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "done in 4.378s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: edu com mail send graphics ftp pub available contact university list faq ca information cs 1993 program sun uk mit\n",
      "Topic #1: don like just know think ve way use right good going make sure ll point got need really time doesn\n",
      "Topic #2: christian think atheism faith pittsburgh new bible radio games alt lot just religion like book read play time subject believe\n",
      "Topic #3: drive disk windows thanks use card drives hard version pc software file using scsi help does new dos controller 16\n",
      "Topic #4: hiv health aids disease april medical care research 1993 light information study national service test led 10 page new drug\n",
      "Topic #5: god people does just good don jesus say israel way life know true fact time law want believe make think\n",
      "Topic #6: 55 10 11 18 15 team game 19 period play 23 12 13 flyers 20 25 22 17 24 16\n",
      "Topic #7: car year just cars new engine like bike good oil insurance better tires 000 thing speed model brake driving performance\n",
      "Topic #8: people said did just didn know time like went think children came come don took years say dead told started\n",
      "Topic #9: key space law government public use encryption earth section security moon probe enforcement keys states lunar military crime surface technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA/LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most straight forward method. SVD is used to reduce the dimension of a TFIDF matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=10000,\n",
    "                             min_df=2, stop_words='english',\n",
    "                             use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf = vectorizer.fit_transform(data_samples)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a pipeline that uses the SVD and Normalizer from sklearn.\n",
    "svd = TruncatedSVD(100)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 771 ms, sys: 112 ms, total: 883 ms\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train the data on the normalizer.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lsa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspecting what the SVD learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "import string\n",
    "from collections import Counter\n",
    "import itertools\n",
    "punct = string.punctuation+' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punct(word):\n",
    "    return ''.join([i for i in word if i not in punct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insepcting the SVD components.\n",
    "top_docs = X_train_lsa[:, 2].argsort()[0:15]\n",
    "check_hold = list(itertools.chain(*[data_samples[i].lower().split() for i in top_docs]))\n",
    "check_hold = [remove_punct(i) for i in check_hold]\n",
    "check_hold = [i for i in check_hold if i not in ENGLISH_STOP_WORDS]\n",
    "term_count = dict(Counter(check_hold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(83, 'god'),\n",
       " (57, ''),\n",
       " (27, 'does'),\n",
       " (19, 'just'),\n",
       " (19, 'faith'),\n",
       " (17, 'people'),\n",
       " (16, 'good'),\n",
       " (16, 'gods'),\n",
       " (15, 'believe'),\n",
       " (14, 'windows'),\n",
       " (13, 'say'),\n",
       " (12, 'exist'),\n",
       " (11, 'time'),\n",
       " (11, 'dont'),\n",
       " (11, 'did'),\n",
       " (10, 'read'),\n",
       " (10, 'makes'),\n",
       " (10, 'like'),\n",
       " (9, 'know'),\n",
       " (9, 'bible'),\n",
       " (8, 'way'),\n",
       " (8, 'suppose'),\n",
       " (8, 'human'),\n",
       " (8, 'dos'),\n",
       " (8, 'doesnt'),\n",
       " (8, 'brothers'),\n",
       " (7, 'think'),\n",
       " (7, 'sin'),\n",
       " (7, 'said'),\n",
       " (7, 'man'),\n",
       " (7, 'life'),\n",
       " (7, 'judge'),\n",
       " (7, 'im'),\n",
       " (7, 'existence'),\n",
       " (7, 'drive'),\n",
       " (7, '2'),\n",
       " (6, 'worship'),\n",
       " (6, 'work'),\n",
       " (6, 'use'),\n",
       " (6, 'nature'),\n",
       " (6, 'make'),\n",
       " (6, 'let'),\n",
       " (6, 'judaism'),\n",
       " (6, 'jews'),\n",
       " (6, 'jesus'),\n",
       " (6, 'heaven'),\n",
       " (6, 'fisher'),\n",
       " (6, 'different'),\n",
       " (6, 'came'),\n",
       " (6, 'actions'),\n",
       " (6, '1'),\n",
       " (5, 'works'),\n",
       " (5, 'wood'),\n",
       " (5, 'using'),\n",
       " (5, 'thought'),\n",
       " (5, 'thing'),\n",
       " (5, 'statement'),\n",
       " (5, 'says'),\n",
       " (5, 'right'),\n",
       " (5, 'reading'),\n",
       " (5, 'purposes'),\n",
       " (5, 'problems'),\n",
       " (5, 'point'),\n",
       " (5, 'mean'),\n",
       " (5, 'lord'),\n",
       " (5, 'looking'),\n",
       " (5, 'josephs'),\n",
       " (5, 'instead'),\n",
       " (5, 'help'),\n",
       " (5, 'far'),\n",
       " (5, 'fact'),\n",
       " (5, 'end'),\n",
       " (5, 'doing'),\n",
       " (5, 'discussion'),\n",
       " (5, 'correct'),\n",
       " (5, 'come'),\n",
       " (5, 'christian'),\n",
       " (5, 'canaan'),\n",
       " (5, 'better'),\n",
       " (5, 'belief'),\n",
       " (4, 'wrong'),\n",
       " (4, 'world'),\n",
       " (4, 'trying'),\n",
       " (4, 'trust'),\n",
       " (4, 'temple'),\n",
       " (4, 'statue'),\n",
       " (4, 'simply'),\n",
       " (4, 'similar'),\n",
       " (4, 'sense'),\n",
       " (4, 'sculptor'),\n",
       " (4, 'scriptures'),\n",
       " (4, 'scripture'),\n",
       " (4, 'role'),\n",
       " (4, 'religious'),\n",
       " (4, 'reason'),\n",
       " (4, 'question'),\n",
       " (4, 'prove'),\n",
       " (4, 'problem'),\n",
       " (4, 'place'),\n",
       " (4, 'pharaoh'),\n",
       " (4, 'men'),\n",
       " (4, 'knows'),\n",
       " (4, 'knot'),\n",
       " (4, 'judas'),\n",
       " (4, 'ive'),\n",
       " (4, 'infants'),\n",
       " (4, 'history'),\n",
       " (4, 'given'),\n",
       " (4, 'genesis'),\n",
       " (4, 'generally'),\n",
       " (4, 'game'),\n",
       " (4, 'fine'),\n",
       " (4, 'fair'),\n",
       " (4, 'example'),\n",
       " (4, 'evil'),\n",
       " (4, 'egypt'),\n",
       " (4, 'course'),\n",
       " (4, 'christ'),\n",
       " (4, 'certainly'),\n",
       " (4, 'c'),\n",
       " (4, 'believed'),\n",
       " (4, 'ask'),\n",
       " (4, 'access'),\n",
       " (4, 'abraham'),\n",
       " (3, 'youve'),\n",
       " (3, 'wrote'),\n",
       " (3, 'worked'),\n",
       " (3, 'women'),\n",
       " (3, 'want'),\n",
       " (3, 'universe'),\n",
       " (3, 'turned'),\n",
       " (3, 'try'),\n",
       " (3, 'truly'),\n",
       " (3, 'torah'),\n",
       " (3, 'told'),\n",
       " (3, 'thats'),\n",
       " (3, 'thanks'),\n",
       " (3, 'strong'),\n",
       " (3, 'spirit'),\n",
       " (3, 'source'),\n",
       " (3, 'situation'),\n",
       " (3, 'second'),\n",
       " (3, 'screen'),\n",
       " (3, 'saying'),\n",
       " (3, 'saved'),\n",
       " (3, 'salvation'),\n",
       " (3, 'religion'),\n",
       " (3, 'proof'),\n",
       " (3, 'program'),\n",
       " (3, 'probably'),\n",
       " (3, 'possibly'),\n",
       " (3, 'possible'),\n",
       " (3, 'play'),\n",
       " (3, 'pilate'),\n",
       " (3, 'pharaohs'),\n",
       " (3, 'person'),\n",
       " (3, 'particular'),\n",
       " (3, 'ones'),\n",
       " (3, 'obey'),\n",
       " (3, 'new'),\n",
       " (3, 'need'),\n",
       " (3, 'natural'),\n",
       " (3, 'moves'),\n",
       " (3, 'moses'),\n",
       " (3, 'moral'),\n",
       " (3, 'meeting'),\n",
       " (3, 'means'),\n",
       " (3, 'making'),\n",
       " (3, 'looked'),\n",
       " (3, 'look'),\n",
       " (3, 'log'),\n",
       " (3, 'leap'),\n",
       " (3, 'lastdrive'),\n",
       " (3, 'julie'),\n",
       " (3, 'judgements'),\n",
       " (3, 'great'),\n",
       " (3, 'father'),\n",
       " (3, 'family'),\n",
       " (3, 'expect'),\n",
       " (3, 'existance'),\n",
       " (3, 'disks'),\n",
       " (3, 'disk'),\n",
       " (3, 'directory'),\n",
       " (3, 'day'),\n",
       " (3, 'danger'),\n",
       " (3, 'copy'),\n",
       " (3, 'control'),\n",
       " (3, 'consider'),\n",
       " (3, 'configsys'),\n",
       " (3, 'coming'),\n",
       " (3, 'city'),\n",
       " (3, 'christians'),\n",
       " (3, 'christianity'),\n",
       " (3, 'chess'),\n",
       " (3, 'brought'),\n",
       " (3, 'books'),\n",
       " (3, 'believing'),\n",
       " (3, 'beliefs'),\n",
       " (3, 'bds'),\n",
       " (3, 'atheists'),\n",
       " (3, 'atheism'),\n",
       " (3, 'antiochus'),\n",
       " (3, 'acts'),\n",
       " (3, 'action'),\n",
       " (3, 'accepted'),\n",
       " (3, '6'),\n",
       " (3, '3'),\n",
       " (2, 'z'),\n",
       " (2, 'youre'),\n",
       " (2, 'yes'),\n",
       " (2, 'xtian'),\n",
       " (2, 'won'),\n",
       " (2, 'woman'),\n",
       " (2, 'wickedness'),\n",
       " (2, 'wicked'),\n",
       " (2, 'warner'),\n",
       " (2, 'wants'),\n",
       " (2, 'walt'),\n",
       " (2, 'view'),\n",
       " (2, 'valid'),\n",
       " (2, 'used'),\n",
       " (2, 'undeniable'),\n",
       " (2, 'uncritically'),\n",
       " (2, 'twice'),\n",
       " (2, 'true'),\n",
       " (2, 'traditional'),\n",
       " (2, 'thwarted'),\n",
       " (2, 'thrown'),\n",
       " (2, 'thinking'),\n",
       " (2, 'things'),\n",
       " (2, 'theory'),\n",
       " (2, 'tells'),\n",
       " (2, 'talking'),\n",
       " (2, 'talk'),\n",
       " (2, 'synagogue'),\n",
       " (2, 'suggestion'),\n",
       " (2, 'study'),\n",
       " (2, 'stop'),\n",
       " (2, 'stood'),\n",
       " (2, 'started'),\n",
       " (2, 'stage'),\n",
       " (2, 'spassky'),\n",
       " (2, 'sins'),\n",
       " (2, 'shame'),\n",
       " (2, 'shall'),\n",
       " (2, 'set'),\n",
       " (2, 'save'),\n",
       " (2, 'sake'),\n",
       " (2, 'saddam'),\n",
       " (2, 'sacrifices'),\n",
       " (2, 'sacrifice'),\n",
       " (2, 'run'),\n",
       " (2, 'ruler'),\n",
       " (2, 'ritual'),\n",
       " (2, 'return'),\n",
       " (2, 'result'),\n",
       " (2, 'reread'),\n",
       " (2, 'requires'),\n",
       " (2, 'require'),\n",
       " (2, 'religions'),\n",
       " (2, 'referred'),\n",
       " (2, 'refer'),\n",
       " (2, 'really'),\n",
       " (2, 'realize'),\n",
       " (2, 'real'),\n",
       " (2, 'rationally'),\n",
       " (2, 'r'),\n",
       " (2, 'questions'),\n",
       " (2, 'punishment'),\n",
       " (2, 'proposes'),\n",
       " (2, 'prophets'),\n",
       " (2, 'promises'),\n",
       " (2, 'predisposed'),\n",
       " (2, 'power'),\n",
       " (2, 'positive'),\n",
       " (2, 'position'),\n",
       " (2, 'player'),\n",
       " (2, 'played'),\n",
       " (2, 'plans'),\n",
       " (2, 'personal'),\n",
       " (2, 'passage'),\n",
       " (2, 'offered'),\n",
       " (2, 'occasional'),\n",
       " (2, 'observations'),\n",
       " (2, 'obeyed'),\n",
       " (2, 'norton'),\n",
       " (2, 'netx'),\n",
       " (2, 'ndd'),\n",
       " (2, 'mythology'),\n",
       " (2, 'myth'),\n",
       " (2, 'movie'),\n",
       " (2, 'movement'),\n",
       " (2, 'mind'),\n",
       " (2, 'merit'),\n",
       " (2, 'merely'),\n",
       " (2, 'meant'),\n",
       " (2, 'meaning'),\n",
       " (2, 'mary'),\n",
       " (2, 'manage'),\n",
       " (2, 'maleness'),\n",
       " (2, 'maintain'),\n",
       " (2, 'machine'),\n",
       " (2, 'loyalty'),\n",
       " (2, 'lot'),\n",
       " (2, 'live'),\n",
       " (2, 'launch'),\n",
       " (2, 'large'),\n",
       " (2, 'language'),\n",
       " (2, 'land'),\n",
       " (2, 'kingdom'),\n",
       " (2, 'judea'),\n",
       " (2, 'jewish'),\n",
       " (2, 'jerusalem'),\n",
       " (2, 'influence'),\n",
       " (2, 'ignore'),\n",
       " (2, 'humans'),\n",
       " (2, 'holocaust'),\n",
       " (2, 'historical'),\n",
       " (2, 'high'),\n",
       " (2, 'hebrews'),\n",
       " (2, 'heart'),\n",
       " (2, 'having'),\n",
       " (2, 'hate'),\n",
       " (2, 'hardly'),\n",
       " (2, 'hard'),\n",
       " (2, 'hand'),\n",
       " (2, 'grounds'),\n",
       " (2, 'gravity'),\n",
       " (2, 'grain'),\n",
       " (2, 'grace'),\n",
       " (2, 'goodness'),\n",
       " (2, 'going'),\n",
       " (2, 'getting'),\n",
       " (2, 'form'),\n",
       " (2, 'forces'),\n",
       " (2, 'fit'),\n",
       " (2, 'filemanager'),\n",
       " (2, 'file'),\n",
       " (2, 'feel'),\n",
       " (2, 'faqs'),\n",
       " (2, 'faq'),\n",
       " (2, 'famine'),\n",
       " (2, 'explain'),\n",
       " (2, 'expected'),\n",
       " (2, 'exists'),\n",
       " (2, 'execute'),\n",
       " (2, 'events'),\n",
       " (2, 'esp'),\n",
       " (2, 'error'),\n",
       " (2, 'epiphanes'),\n",
       " (2, 'enter'),\n",
       " (2, 'english'),\n",
       " (2, 'earlier'),\n",
       " (2, 'duty'),\n",
       " (2, 'drives'),\n",
       " (2, 'doubt'),\n",
       " (2, 'doolittle'),\n",
       " (2, 'documents'),\n",
       " (2, 'dk'),\n",
       " (2, 'disney'),\n",
       " (2, 'disaster'),\n",
       " (2, 'direction'),\n",
       " (2, 'direct'),\n",
       " (2, 'difficulties'),\n",
       " (2, 'difficult'),\n",
       " (2, 'dictator'),\n",
       " (2, 'destroy'),\n",
       " (2, 'deny'),\n",
       " (2, 'deleted'),\n",
       " (2, 'decided'),\n",
       " (2, 'decent'),\n",
       " (2, 'death'),\n",
       " (2, 'd'),\n",
       " (2, 'cut'),\n",
       " (2, 'cowardice'),\n",
       " (2, 'corrupted'),\n",
       " (2, 'contrary'),\n",
       " (2, 'contradiction'),\n",
       " (2, 'continued'),\n",
       " (2, 'considered'),\n",
       " (2, 'configurations'),\n",
       " (2, 'conclusion'),\n",
       " (2, 'clearly'),\n",
       " (2, 'central'),\n",
       " (2, 'cases'),\n",
       " (2, 'case'),\n",
       " (2, 'captivity'),\n",
       " (2, 'canaanites'),\n",
       " (2, 'bring'),\n",
       " (2, 'born'),\n",
       " (2, 'bobby'),\n",
       " (2, 'bit'),\n",
       " (2, 'best'),\n",
       " (2, 'bad'),\n",
       " (2, 'backup'),\n",
       " (2, 'babylonians'),\n",
       " (2, 'babylonian'),\n",
       " (2, 'b'),\n",
       " (2, 'away'),\n",
       " (2, 'author'),\n",
       " (2, 'attain'),\n",
       " (2, 'art'),\n",
       " (2, 'argument'),\n",
       " (2, 'appreciated'),\n",
       " (2, 'answer'),\n",
       " (2, 'andrews'),\n",
       " (2, 'alleged'),\n",
       " (2, 'agree'),\n",
       " (2, 'actually'),\n",
       " (2, 'according'),\n",
       " (2, 'accomplish'),\n",
       " (2, 'accept'),\n",
       " (2, 'able'),\n",
       " (2, '768x1024'),\n",
       " (2, '525'),\n",
       " (2, '5'),\n",
       " (2, '35'),\n",
       " (1, 'y'),\n",
       " (1, 'xtianity'),\n",
       " (1, 'xcopy'),\n",
       " (1, 'writings'),\n",
       " (1, 'writing'),\n",
       " (1, 'writers'),\n",
       " (1, 'wp'),\n",
       " (1, 'worthless'),\n",
       " (1, 'worry'),\n",
       " (1, 'worldwide'),\n",
       " (1, 'workings'),\n",
       " (1, 'working'),\n",
       " (1, 'workgroups'),\n",
       " (1, 'workable'),\n",
       " (1, 'words'),\n",
       " (1, 'wonder'),\n",
       " (1, 'wishful'),\n",
       " (1, 'wisdom'),\n",
       " (1, 'winwinword'),\n",
       " (1, 'winvn'),\n",
       " (1, 'winsockdll'),\n",
       " (1, 'wins'),\n",
       " (1, 'willing'),\n",
       " (1, 'wife'),\n",
       " (1, 'wide'),\n",
       " (1, 'whoes'),\n",
       " (1, 'whatnot'),\n",
       " (1, 'werent'),\n",
       " (1, 'webster'),\n",
       " (1, 'weak'),\n",
       " (1, 'ways'),\n",
       " (1, 'water'),\n",
       " (1, 'watching'),\n",
       " (1, 'washing'),\n",
       " (1, 'wages'),\n",
       " (1, 'wag'),\n",
       " (1, 'w4wg'),\n",
       " (1, 'violently'),\n",
       " (1, 'views'),\n",
       " (1, 'viceroy'),\n",
       " (1, 'viable'),\n",
       " (1, 'venial'),\n",
       " (1, 'utility'),\n",
       " (1, 'utilities'),\n",
       " (1, 'utah'),\n",
       " (1, 'usually'),\n",
       " (1, 'usual'),\n",
       " (1, 'user'),\n",
       " (1, 'useless'),\n",
       " (1, 'upbringing'),\n",
       " (1, 'unworthy'),\n",
       " (1, 'unshaken'),\n",
       " (1, 'unless'),\n",
       " (1, 'universally'),\n",
       " (1, 'undertook'),\n",
       " (1, 'understands'),\n",
       " (1, 'unbaptized'),\n",
       " (1, 'ultra'),\n",
       " (1, 'typecast'),\n",
       " (1, 'type'),\n",
       " (1, 'turn'),\n",
       " (1, 'truths'),\n",
       " (1, 'truth'),\n",
       " (1, 'trusting'),\n",
       " (1, 'trumpet'),\n",
       " (1, 'truebelieving'),\n",
       " (1, 'trouble'),\n",
       " (1, 'trident'),\n",
       " (1, 'tribal'),\n",
       " (1, 'trendy'),\n",
       " (1, 'transfers'),\n",
       " (1, 'touch'),\n",
       " (1, 'total'),\n",
       " (1, 'took'),\n",
       " (1, 'tom'),\n",
       " (1, 'token'),\n",
       " (1, 'tm'),\n",
       " (1, 'titus'),\n",
       " (1, 'times'),\n",
       " (1, 'till'),\n",
       " (1, 'ties'),\n",
       " (1, 'threaten'),\n",
       " (1, 'thirds'),\n",
       " (1, 'thinks'),\n",
       " (1, 'theologians'),\n",
       " (1, 'theme'),\n",
       " (1, 'thank'),\n",
       " (1, 'tendancy'),\n",
       " (1, 'tend'),\n",
       " (1, 'temporal'),\n",
       " (1, 'telling'),\n",
       " (1, 'teachings'),\n",
       " (1, 'teaching'),\n",
       " (1, 'teach'),\n",
       " (1, 'tcpip'),\n",
       " (1, 'taken'),\n",
       " (1, 'tabloids'),\n",
       " (1, 'syn'),\n",
       " (1, 'symptom'),\n",
       " (1, 'switching'),\n",
       " (1, 'suspension'),\n",
       " (1, 'survival'),\n",
       " (1, 'surface'),\n",
       " (1, 'sure'),\n",
       " (1, 'supposedly'),\n",
       " (1, 'supported'),\n",
       " (1, 'supermarket'),\n",
       " (1, 'sum'),\n",
       " (1, 'suggest'),\n",
       " (1, 'successfailure'),\n",
       " (1, 'succeed'),\n",
       " (1, 'substance'),\n",
       " (1, 'subject'),\n",
       " (1, 'studio'),\n",
       " (1, 'studied'),\n",
       " (1, 'stubbornness'),\n",
       " (1, 'stronger'),\n",
       " (1, 'strings'),\n",
       " (1, 'story'),\n",
       " (1, 'stirred'),\n",
       " (1, 'stayed'),\n",
       " (1, 'status'),\n",
       " (1, 'station'),\n",
       " (1, 'statements'),\n",
       " (1, 'state'),\n",
       " (1, 'start'),\n",
       " (1, 'star'),\n",
       " (1, 'standing'),\n",
       " (1, 'standards'),\n",
       " (1, 'stamp'),\n",
       " (1, 'st'),\n",
       " (1, 'spritual'),\n",
       " (1, 'spoils'),\n",
       " (1, 'special'),\n",
       " (1, 'space'),\n",
       " (1, 'sort'),\n",
       " (1, 'solved'),\n",
       " (1, 'sold'),\n",
       " (1, 'sockets'),\n",
       " (1, 'socalled'),\n",
       " (1, 'smooth'),\n",
       " (1, 'smiling'),\n",
       " (1, 'smcapboldfontgod'),\n",
       " (1, 'smartdrv'),\n",
       " (1, 'smartdrive'),\n",
       " (1, 'small'),\n",
       " (1, 'slow'),\n",
       " (1, 'slip'),\n",
       " (1, 'sleep'),\n",
       " (1, 'slavery'),\n",
       " (1, 'slaughtering'),\n",
       " (1, 'skill'),\n",
       " (1, 'sistine'),\n",
       " (1, 'sinned'),\n",
       " (1, 'sinful'),\n",
       " (1, 'sincerity'),\n",
       " (1, 'simple'),\n",
       " (1, 'similarly'),\n",
       " (1, 'sign'),\n",
       " (1, 'sic'),\n",
       " (1, 'shortstories'),\n",
       " (1, 'shortcomings'),\n",
       " (1, 'shaped'),\n",
       " (1, 'shakier'),\n",
       " (1, 'series'),\n",
       " (1, 'serbs'),\n",
       " (1, 'serbians'),\n",
       " (1, 'sell'),\n",
       " (1, 'seen'),\n",
       " (1, 'sectors'),\n",
       " (1, 'seals'),\n",
       " (1, 'sd'),\n",
       " (1, 'scrutiny'),\n",
       " (1, 'scriptural'),\n",
       " (1, 'screwwing'),\n",
       " (1, 'saving'),\n",
       " (1, 'sarah'),\n",
       " (1, 'sale'),\n",
       " (1, 'runs'),\n",
       " (1, 'running'),\n",
       " (1, 'rules'),\n",
       " (1, 'round'),\n",
       " (1, 'romans'),\n",
       " (1, 'robbery'),\n",
       " (1, 'rob'),\n",
       " (1, 'ring'),\n",
       " (1, 'righteousness'),\n",
       " (1, 'righteous'),\n",
       " (1, 'revise'),\n",
       " (1, 'returning'),\n",
       " (1, 'retentive'),\n",
       " (1, 'results'),\n",
       " (1, 'restored'),\n",
       " (1, 'rest'),\n",
       " (1, 'response'),\n",
       " (1, 'respect'),\n",
       " (1, 'resistance'),\n",
       " (1, 'reset'),\n",
       " (1, 'research'),\n",
       " (1, 'requirements'),\n",
       " (1, 'report'),\n",
       " (1, 'reply'),\n",
       " (1, 'replied'),\n",
       " (1, 'replaced'),\n",
       " (1, 'repeat'),\n",
       " (1, 'renewing'),\n",
       " (1, 'rendered'),\n",
       " (1, 'remember'),\n",
       " (1, 'rejected'),\n",
       " (1, 'regularly'),\n",
       " (1, 'regeneration'),\n",
       " (1, 'regards'),\n",
       " (1, 'refused'),\n",
       " (1, 'refrained'),\n",
       " (1, 'refering'),\n",
       " (1, 'referencing'),\n",
       " (1, 'redemption'),\n",
       " (1, 'redeem'),\n",
       " (1, 'reconciliation'),\n",
       " (1, 'reconciled'),\n",
       " (1, 'recommend'),\n",
       " (1, 'rebooting'),\n",
       " (1, 'reboot'),\n",
       " (1, 'reasonableness'),\n",
       " (1, 'reasonable'),\n",
       " (1, 'realized'),\n",
       " (1, 'reality'),\n",
       " (1, 'readingwriting'),\n",
       " (1, 'reader'),\n",
       " (1, 'rape'),\n",
       " (1, 'raises'),\n",
       " (1, 'radical'),\n",
       " (1, 'race'),\n",
       " (1, 'rabbis'),\n",
       " (1, 'rabbi'),\n",
       " (1, 'questioni'),\n",
       " (1, 'queen'),\n",
       " (1, 'quarrel'),\n",
       " (1, 'qualify'),\n",
       " (1, 'putting'),\n",
       " (1, 'purging'),\n",
       " (1, 'purgatory'),\n",
       " (1, 'purely'),\n",
       " (1, 'puppet'),\n",
       " (1, 'punishable'),\n",
       " (1, 'punish'),\n",
       " (1, 'pulling'),\n",
       " (1, 'psalm'),\n",
       " (1, 'providence'),\n",
       " (1, 'provide'),\n",
       " (1, 'prostitution'),\n",
       " (1, 'prophecy'),\n",
       " (1, 'pronouns'),\n",
       " (1, 'pronoun'),\n",
       " (1, 'promised'),\n",
       " (1, 'promise'),\n",
       " (1, 'progress'),\n",
       " (1, 'production'),\n",
       " (1, 'procede'),\n",
       " (1, 'pro'),\n",
       " (1, 'privately'),\n",
       " (1, 'printer'),\n",
       " (1, 'preserved'),\n",
       " (1, 'presentation'),\n",
       " (1, 'presence'),\n",
       " (1, 'prescribed'),\n",
       " (1, 'preface'),\n",
       " (1, 'predicted'),\n",
       " (1, 'precisely'),\n",
       " (1, 'powerful'),\n",
       " (1, 'potter'),\n",
       " (1, 'possess'),\n",
       " (1, 'portrayed'),\n",
       " (1, 'portion'),\n",
       " (1, 'population'),\n",
       " (1, 'poppins'),\n",
       " (1, 'pop'),\n",
       " (1, 'polytheism'),\n",
       " (1, 'politics'),\n",
       " (1, 'politically'),\n",
       " (1, 'political'),\n",
       " (1, 'polite'),\n",
       " (1, 'politcal'),\n",
       " (1, 'pointless'),\n",
       " (1, 'pointers'),\n",
       " (1, 'playing'),\n",
       " (1, 'pilgrims'),\n",
       " (1, 'piece'),\n",
       " (1, 'phrase'),\n",
       " (1, 'philosophy'),\n",
       " (1, 'philosophic'),\n",
       " (1, 'personally'),\n",
       " (1, 'persians'),\n",
       " (1, 'performing'),\n",
       " (1, 'perfectly'),\n",
       " (1, 'pdfreeware'),\n",
       " (1, 'pc'),\n",
       " (1, 'patron'),\n",
       " (1, 'passed'),\n",
       " (1, 'partner'),\n",
       " (1, 'particularly'),\n",
       " (1, 'partents'),\n",
       " (1, 'paper'),\n",
       " (1, 'painted'),\n",
       " (1, 'oxymoronica'),\n",
       " (1, 'overall'),\n",
       " (1, 'outside'),\n",
       " (1, 'outrage'),\n",
       " (1, 'oscar'),\n",
       " (1, 'os2'),\n",
       " (1, 'originals'),\n",
       " (1, 'original'),\n",
       " (1, 'origianl'),\n",
       " (1, 'oriental'),\n",
       " (1, 'organization'),\n",
       " (1, 'order'),\n",
       " (1, 'oppression'),\n",
       " (1, 'oppressed'),\n",
       " (1, 'opposed'),\n",
       " (1, 'opportunity'),\n",
       " (1, 'opinion'),\n",
       " (1, 'omitted'),\n",
       " (1, 'older'),\n",
       " (1, 'offshoots'),\n",
       " (1, 'offering'),\n",
       " (1, 'offer'),\n",
       " (1, 'offend'),\n",
       " (1, 'occasions'),\n",
       " (1, 'obviously'),\n",
       " (1, 'obvious'),\n",
       " (1, 'observtions'),\n",
       " (1, 'observers'),\n",
       " (1, 'observation'),\n",
       " (1, 'observances'),\n",
       " (1, 'obeying'),\n",
       " (1, 'nuptiis'),\n",
       " (1, 'numbers'),\n",
       " (1, 'nu45'),\n",
       " (1, 'novice'),\n",
       " (1, 'novell'),\n",
       " (1, 'nonexistence'),\n",
       " (1, 'nondiscriminatory'),\n",
       " (1, 'nodding'),\n",
       " (1, 'nobuya'),\n",
       " (1, 'nicer'),\n",
       " (1, 'nice'),\n",
       " (1, 'news'),\n",
       " (1, 'neuter'),\n",
       " (1, 'network'),\n",
       " (1, 'nervously'),\n",
       " (1, 'needless'),\n",
       " (1, 'nebuchadnezzar'),\n",
       " (1, 'ndis'),\n",
       " (1, 'naturally'),\n",
       " (1, 'myths'),\n",
       " (1, 'muslims'),\n",
       " (1, 'muslim'),\n",
       " (1, 'murderous'),\n",
       " (1, 'murder'),\n",
       " (1, 'multiple'),\n",
       " (1, 'ms'),\n",
       " (1, 'moved'),\n",
       " (1, 'motive'),\n",
       " (1, 'mother'),\n",
       " (1, 'moslems'),\n",
       " (1, 'moron'),\n",
       " (1, 'morning'),\n",
       " (1, 'morality'),\n",
       " (1, 'mor'),\n",
       " (1, 'moons'),\n",
       " (1, 'month'),\n",
       " (1, 'modern'),\n",
       " (1, 'mode'),\n",
       " (1, 'misunderstood'),\n",
       " (1, 'mistake'),\n",
       " (1, 'missing'),\n",
       " (1, 'missed'),\n",
       " (1, 'misguided'),\n",
       " (1, 'misfortune'),\n",
       " (1, 'michelangelo'),\n",
       " (1, 'met'),\n",
       " (1, 'messiahs'),\n",
       " (1, 'mercy'),\n",
       " (1, 'memorable'),\n",
       " (1, 'meet'),\n",
       " (1, 'media'),\n",
       " (1, 'meaningless'),\n",
       " (1, 'matt'),\n",
       " (1, 'mark'),\n",
       " (1, 'mapping'),\n",
       " (1, 'manner'),\n",
       " (1, 'male'),\n",
       " (1, 'malcolm'),\n",
       " (1, 'magnificent'),\n",
       " (1, 'macedonians'),\n",
       " (1, 'lying'),\n",
       " (1, 'luck'),\n",
       " (1, 'loves'),\n",
       " (1, 'love'),\n",
       " (1, 'loss'),\n",
       " (1, 'loses'),\n",
       " (1, 'lose'),\n",
       " (1, 'locks'),\n",
       " (1, 'local'),\n",
       " (1, 'living'),\n",
       " (1, 'lives'),\n",
       " (1, 'listmember'),\n",
       " (1, 'listed'),\n",
       " (1, 'line'),\n",
       " (1, 'likely'),\n",
       " (1, 'liked'),\n",
       " (1, 'lifetime'),\n",
       " (1, 'lifes'),\n",
       " (1, 'lib'),\n",
       " (1, 'leviticus'),\n",
       " (1, 'legendary'),\n",
       " (1, 'legend'),\n",
       " (1, 'legal'),\n",
       " (1, 'left'),\n",
       " (1, 'lee'),\n",
       " (1, 'lecture'),\n",
       " (1, 'leaving'),\n",
       " (1, 'leaders'),\n",
       " (1, 'lay'),\n",
       " (1, 'lawsmcapboldfont'),\n",
       " (1, 'later'),\n",
       " (1, 'largely'),\n",
       " (1, 'lady'),\n",
       " (1, 'lack'),\n",
       " (1, 'knowing'),\n",
       " (1, 'knight'),\n",
       " (1, 'killie'),\n",
       " (1, 'killed'),\n",
       " (1, 'kierkegaard'),\n",
       " (1, 'kicked'),\n",
       " (1, 'kept'),\n",
       " (1, 'justly'),\n",
       " (1, 'justified'),\n",
       " (1, 'justicewell'),\n",
       " (1, 'judging'),\n",
       " (1, 'judgement'),\n",
       " (1, 'jowls'),\n",
       " (1, 'journey'),\n",
       " (1, 'joseph'),\n",
       " (1, 'john'),\n",
       " (1, 'james'),\n",
       " (1, 'jack'),\n",
       " (1, 'israelites'),\n",
       " (1, 'israel'),\n",
       " (1, 'isolated'),\n",
       " (1, 'irreversibly'),\n",
       " (1, 'irrelevant'),\n",
       " (1, 'io'),\n",
       " (1, 'invented'),\n",
       " (1, 'invent'),\n",
       " (1, 'invalid'),\n",
       " (1, 'interruption'),\n",
       " (1, 'interpretations'),\n",
       " (1, 'intermarried'),\n",
       " (1, 'interior'),\n",
       " (1, 'interested'),\n",
       " (1, 'intentions'),\n",
       " (1, 'intent'),\n",
       " (1, 'intend'),\n",
       " (1, 'integrity'),\n",
       " (1, 'insufferable'),\n",
       " (1, 'instruments'),\n",
       " (1, 'instructive'),\n",
       " (1, 'instance'),\n",
       " (1, 'installed'),\n",
       " (1, 'install'),\n",
       " (1, 'insight'),\n",
       " (1, 'inherently'),\n",
       " (1, 'inference'),\n",
       " (1, 'infallible'),\n",
       " (1, 'inevitably'),\n",
       " (1, 'induced'),\n",
       " (1, 'individual'),\n",
       " (1, 'indescribably'),\n",
       " (1, 'incidents'),\n",
       " (1, 'improvements'),\n",
       " (1, 'impressed'),\n",
       " (1, 'impossible'),\n",
       " (1, 'important'),\n",
       " (1, 'imply'),\n",
       " (1, 'imo'),\n",
       " (1, 'ill'),\n",
       " (1, 'ignoring'),\n",
       " (1, 'idolatry'),\n",
       " (1, 'idea'),\n",
       " (1, 'ide'),\n",
       " (1, 'ibm'),\n",
       " (1, 'hussein'),\n",
       " (1, 'hung'),\n",
       " (1, 'humanity'),\n",
       " (1, 'hours'),\n",
       " (1, 'hour'),\n",
       " (1, 'hope'),\n",
       " (1, 'honor'),\n",
       " (1, 'holy'),\n",
       " (1, 'holds'),\n",
       " (1, 'holding'),\n",
       " (1, 'hold'),\n",
       " (1, 'historians'),\n",
       " (1, 'highly'),\n",
       " (1, 'higgy'),\n",
       " (1, 'higashiyama'),\n",
       " (1, 'hes'),\n",
       " (1, 'heroes'),\n",
       " (1, 'heresy'),\n",
       " (1, 'hepburn'),\n",
       " (1, 'hefty'),\n",
       " (1, 'hebrew'),\n",
       " (1, 'hearing'),\n",
       " (1, 'heard'),\n",
       " (1, 'hear'),\n",
       " (1, 'head'),\n",
       " (1, 'hatred'),\n",
       " (1, 'hardware'),\n",
       " (1, 'hardened'),\n",
       " (1, 'harden'),\n",
       " (1, 'happens'),\n",
       " (1, 'happened'),\n",
       " (1, 'hannibal'),\n",
       " (1, 'handle'),\n",
       " (1, 'hallelujah'),\n",
       " (1, 'hagar'),\n",
       " (1, 'gurus'),\n",
       " (1, 'ground'),\n",
       " (1, 'greeks'),\n",
       " (1, 'greatly'),\n",
       " (1, 'greatest'),\n",
       " (1, 'graphics'),\n",
       " (1, 'grand'),\n",
       " (1, 'got'),\n",
       " (1, 'gone'),\n",
       " (1, 'goes'),\n",
       " (1, 'glad'),\n",
       " (1, 'giving'),\n",
       " (1, 'gives'),\n",
       " (1, 'genuineness'),\n",
       " (1, 'genocide'),\n",
       " (1, 'generations'),\n",
       " (1, 'general'),\n",
       " (1, 'gateway'),\n",
       " (1, 'gas'),\n",
       " (1, 'future'),\n",
       " (1, 'furthermore'),\n",
       " (1, 'fulfilled'),\n",
       " (1, 'fulfil'),\n",
       " (1, 'friends'),\n",
       " (1, 'free'),\n",
       " (1, 'frame'),\n",
       " (1, 'fourth'),\n",
       " (1, 'fortunate'),\n",
       " (1, 'formal'),\n",
       " (1, 'forgotten'),\n",
       " (1, 'forgiven'),\n",
       " (1, 'forgetting'),\n",
       " (1, 'forever'),\n",
       " (1, 'foothold'),\n",
       " (1, 'follows'),\n",
       " (1, 'following'),\n",
       " (1, 'followers'),\n",
       " (1, 'follower'),\n",
       " (1, 'followed'),\n",
       " (1, 'follow'),\n",
       " (1, 'fo'),\n",
       " (1, 'floppy'),\n",
       " (1, 'flaw'),\n",
       " (1, 'fishers'),\n",
       " (1, 'firm'),\n",
       " (1, 'finished'),\n",
       " (1, 'fingers'),\n",
       " (1, 'finds'),\n",
       " (1, 'finding'),\n",
       " (1, 'files'),\n",
       " (1, 'fidelity'),\n",
       " (1, 'fiction'),\n",
       " (1, 'fertility'),\n",
       " (1, 'female'),\n",
       " (1, 'felt'),\n",
       " (1, 'fellow'),\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(term_count.values(), term_count.keys())))[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 0.535s.\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "done in 2.102s.\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: people just like time don say really know way things make think right said did want ve probably work years\n",
      "Topic #1: windows thanks using help need hi work know use looking mail software does used pc video available running info advance\n",
      "Topic #2: god does true read know say believe subject says religion mean question point jesus people book christian mind understand matter\n",
      "Topic #3: thanks know like interested mail just want new send edu list does bike thing email reply post wondering hear heard\n",
      "Topic #4: time new 10 year sale old offer 20 16 15 great 30 weeks good test model condition 11 14 power\n",
      "Topic #5: use number com government new university data states information talk phone right including security provide control following long used research\n",
      "Topic #6: edu try file soon remember problem com program hope mike space article wrong library short include win little couldn sun\n",
      "Topic #7: year world team game play won win games season maybe case second does did series playing nhl fact said points\n",
      "Topic #8: think don drive need hard make people mac read going pretty try sure order means trying apple case bit drives\n",
      "Topic #9: just good use way got like ll doesn want sure don doing thought does wrong right better make stuff speed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese Restaurant Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e41e31889a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tables' is not defined"
     ]
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Play with different concentrations\n",
    "for concentration in [0.0, 0.5, 1.0]:\n",
    "\n",
    "    # First customer always sits at the first table\n",
    "    # To do otherwise would be insanity\n",
    "    tables = [1]\n",
    "\n",
    "    # n=1 is the first customer \n",
    "    for n in range(2,1000):\n",
    "\n",
    "        # Gen random number 0~1\n",
    "        rand = random.random()\n",
    "\n",
    "        p_total = 0\n",
    "        existing_table = False\n",
    "\n",
    "        for index, count in enumerate(tables):\n",
    "\n",
    "            prob = count / (n + concentration)\n",
    "\n",
    "            p_total += prob\n",
    "            if rand < p_total:\n",
    "                tables[index] += 1\n",
    "                existing_table = True\n",
    "                break\n",
    "\n",
    "        # New table!!\n",
    "        if not existing_table:\n",
    "             tables.append(1)\n",
    "\n",
    "    for index, count in enumerate(tables):\n",
    "        print(index, \"X\", (count/100), count)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
